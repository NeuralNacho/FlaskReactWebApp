# This file will train a neural network from date generated by generate_training_data.py

import numpy as np
import tensorflow as tf
from keras.layers import Conv2D, Flatten, Dense, Activation
from keras.models import Sequential, load_model
from keras.callbacks import LearningRateScheduler, TensorBoard
from sklearn import model_selection
from sklearn import preprocessing

# Instantiate the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(8, 8, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='linear')
])

# # model = load_model('C:/Users/angus/AppData/Desktop/ElasticBeanstalkWebApp/backend/Othello/depth_0_model.keras')
# model.compile(optimizer='adam', loss='mean_squared_error')

model = Sequential()

# Add Convolutional layers with residual connections
# Note testing shows model is slower with batch normalisation
# Definitely want padding so neural network can detect important patterns at edge of board
model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', input_shape = (8, 8, 2))) 
model.add(Activation('relu'))

# Residual Block 1
model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same'))
model.add(Activation('relu'))
model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same'))
model.add(Activation('relu'))

# Add more Convolutional layers and Residual Blocks as needed

# Flatten and fully connected layers
model.add(Flatten())
model.add(Dense(256, activation = 'relu'))
model.add(Dense(128, activation = 'relu'))
# Value head

model.add(Dense(1, activation = 'sigmoid'))

# Compile the model with appropriate loss functions and optimizer
model.compile(optimizer = 'adam', loss = 'mean_squared_error')
model.summary()

def lr_schedule(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)  # Exponential decay
lr_scheduler = LearningRateScheduler(lr_schedule)

training_data = np.load('./backend/Othello/Neural_Net_Training/Training_Data/depth_0.npy', \
                      allow_pickle = True)
positions = training_data.item()['positions'][1:100000]
evaluations = training_data.item()['evaluations'][1:100000]
scaler = preprocessing.MinMaxScaler()
normalised_evaluations = scaler.fit_transform(evaluations.reshape(-1, 1))
X_train, X_val, y_train, y_val = model_selection.train_test_split\
    (positions, normalised_evaluations, test_size = 0.2, random_state = 42)

# Define the TensorBoard callback
log_dir = "logs/"  # Provide a directory to store TensorBoard logs
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq = 1, update_freq = 'batch')
# Run tensorboard --logdir=logs/ to view callback

model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 20, batch_size = 1024, callbacks = [tensorboard_callback])
model.save('./backend/Othello/Neural_Net_Training/Trained_Models/test_model_2.keras')